# This base image comes shipped with java 11 (needed for scala)
# The openj9 version might be more RAM efficient, but suffers on CPU efficiency
# More details can be found:https://www.royvanrijn.com/blog/2018/05/openj9-jvm-shootout/
# FROM adoptopenjdk:11.0.8_10-jdk-openj9-0.21.0-bionic
# FROM adoptopenjdk:11.0.8_10-jdk-hotspot-bionic
# Tag: 11.0.9_11-jdk-hotspot
FROM adoptopenjdk:11.0.9_11-jdk-hotspot-focal

LABEL author="Yingding Wang"
LABEL version="0.1"

# Docker Multistage build // copy from python:3.6 image
# https://docs.docker.com/develop/develop-images/multistage-build/
# COPY --from=python:3.6 / /

# Set env variables
ENV DAEMON_RUN=true
ENV SPARK_VERSION=3.0.1
ENV HADOOP_VERSION=3.2
ENV SCALA_VERSION=2.12.12
ENV SCALA_HOME=/usr/share/scala
ENV SPARK_HOME=/spark
ENV SPARK_OPTS="--driver-java-options='-Xms1024M -Xmx4096M -Dlog4j.logLevel=info -Dio.netty.tryReflectionSetAccessible=true'"

# ENV SPARK_OPTS --driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.logLevel=info

# ENV PYTHONPATH $SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.7-src.zip

# Add additional repo's for apk to use
# RUN echo http://mirror.yandex.ru/mirrors/alpine/v3.3/main > /etc/apk/repositories; \
#    echo http://mirror.yandex.ru/mirrors/alpine/v3.3/community >> /etc/apk/repositories

# Update commands in Ubuntu Bionic 18.4
# RUN apk --update add wget tar bash coreutils procps openssl
# Software properties common for python3
# RUN apt-get update && apt-get install -y apt-utils
# debconf: delaying package configuration, since apt-utils is not installed can be safely ignored
RUN apt-get update && apt-get install -y curl vim wget software-properties-common ssh net-tools ca-certificates iputils-ping inetutils-telnet maven ivy

# Tutorial
# https://github.com/mvillarrealb/docker-spark-cluster/blob/master/docker/base/Dockerfile

# Install Scala
# RUN apk add --no-cache --virtual=.build-dependencies wget ca-certificates && \
#     apk add --no-cache bash && \
#     cd "/tmp" && \
#     wget "https://downloads.typesafe.com/scala/${SCALA_VERSION}/scala-${SCALA_VERSION}.tgz" && \
#     tar xzf "scala-${SCALA_VERSION}.tgz" && \
#    mkdir "${SCALA_HOME}" && \
#     rm "/tmp/scala-${SCALA_VERSION}/bin/"*.bat && \
#     mv "/tmp/scala-${SCALA_VERSION}/bin" "/tmp/scala-${SCALA_VERSION}/lib" "${SCALA_HOME}" && \
#     ln -s "${SCALA_HOME}/bin/"* "/usr/bin/" && \
#     apk del .build-dependencies && \
#     rm -rf "/tmp/"*

# wget --no-verbose "https://downloads.typesafe.com/scala/${SCALA_VERSION}/scala-${SCALA_VERSION}.tgz"
RUN cd "/tmp" && \
    wget --no-verbose "https://downloads.typesafe.com/scala/${SCALA_VERSION}/scala-${SCALA_VERSION}.tgz" && \
    tar -xvzf "scala-${SCALA_VERSION}.tgz" && \
    mkdir "${SCALA_HOME}" && \
    rm "/tmp/scala-${SCALA_VERSION}/bin/"*.bat && \
    mv "/tmp/scala-${SCALA_VERSION}/bin" "/tmp/scala-${SCALA_VERSION}/lib" "${SCALA_HOME}" && \
    ln -s "${SCALA_HOME}/bin/"* "/usr/bin/" && \
    rm -rf "/tmp/"*

RUN export PATH="/usr/local/sbt/bin:$PATH" && apt-get update && apt-get install ca-certificates wget tar && mkdir -p "/usr/local/sbt"
# && wget -qO - --no-check-certificate "https://github.com/sbt/sbt/releases/download/v1.2.8/sbt-1.2.8.tgz" | tar xz -C /usr/local/sbt --strip-components=1 && sbt sbtVersion
# RUN export PATH="/usr/local/sbt/bin:$PATH" &&  apk update && apk add ca-certificates wget tar && mkdir -p "/usr/local/sbt"

# Get Apache Spark
# RUN wget http://mirror.ox.ac.uk/sites/rsync.apache.org/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz
RUN wget --no-verbose https://mirror.dkd.de/apache/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz
# RUN wget https://www.apache.org/dyn/closer.lua/spark/

# Install Spark and move it to the folder "/spark" and then add this location to the PATH env variable
RUN tar -xzf spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz && \
    mv spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} /spark && \
    rm spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz && \
    export PATH=$SPARK_HOME/bin:$PATH

# Install jars needed for communication with Azure
# RUN wget https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-azure/${HADOOP_VERSION}.0/hadoop-azure-${HADOOP_VERSION}.0.jar -P $SPARK_HOME/jars/ && \
#     wget https://repo1.maven.org/maven2/com/microsoft/azure/azure-storage/8.6.3/azure-storage-8.6.3.jar -P $SPARK_HOME/jars/


# Handling PID 1 subprocess
# Add Tini
ENV TINI_VERSION v0.19.0
ADD https://github.com/krallin/tini/releases/download/${TINI_VERSION}/tini /tini
RUN chmod +x /tini

